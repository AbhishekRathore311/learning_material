{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sequence_model import HangmanGRU\n",
    "from get_current_epoch_data import get_current_epoch_data\n",
    "from get_current_batch_data import get_current_batch_data\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    total_epochs = 3000,\n",
    "    encoded_train_words_location = None,\n",
    "    encoded_test_words_location = None,\n",
    "    batch_size = 4000,\n",
    "    vocab_size = 26,\n",
    "    cuda = False,\n",
    "    reset_after = 300,\n",
    "    save_every = 300,\n",
    "    model_output_location = None,\n",
    "    gru_hidden_dim = 512,\n",
    "    gru_num_layers = 2,\n",
    "    char_embedding_dim = 128,\n",
    "    missed_char_linear_dim = 256,\n",
    "    nn_hidden_dim = 256,\n",
    "    gru_dropout = 0.3,\n",
    "    learning_rate = 0.0005\n",
    "):\n",
    "    ## Load model and set it to train mode\n",
    "    model = HangmanGRU(\n",
    "        vocab_size = vocab_size,\n",
    "        gru_hidden_dim = gru_hidden_dim,\n",
    "        gru_num_layers = gru_num_layers,\n",
    "        char_embedding_dim = char_embedding_dim,\n",
    "        missed_char_linear_dim = missed_char_linear_dim,\n",
    "        nn_hidden_dim = nn_hidden_dim,\n",
    "        gru_dropout = gru_dropout,\n",
    "        learning_rate = learning_rate\n",
    "    )\n",
    "    model.train()\n",
    "\n",
    "    ## Get encoded_train_word_list\n",
    "    encoded_train_word_list = pickle.load(open(encoded_train_words_location, \"rb\"))\n",
    "    \n",
    "    ## Get encoded_test_word_list\n",
    "    encoded_test_word_list = pickle.load(open(encoded_test_words_location, \"rb\"))\n",
    "\n",
    "    ## Lists to store losses\n",
    "    train_loss_list = []\n",
    "    train_miss_penalty_list = []\n",
    "    test_loss_list = []\n",
    "    test_miss_penalty_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    ## Loop over Train Data\n",
    "    for epoch in range(1, total_epochs+1):\n",
    "        ## Initialize epoch loss\n",
    "        train_loss = 0.0\n",
    "        train_miss_penalty = 0.0\n",
    "\n",
    "        ## Get cur_epoch_train_data_list\n",
    "        if(((epoch - 1) % reset_after) == 0):\n",
    "            cur_epoch_train_data_list = get_current_epoch_data(\n",
    "                encoded_word_list = encoded_train_word_list, \n",
    "                epoch_number = epoch, \n",
    "                total_epochs = total_epochs,\n",
    "                vocab_size = vocab_size\n",
    "            )\n",
    "\n",
    "        ## Loop over batches\n",
    "        no_batches = int(math.ceil(len(cur_epoch_train_data_list) / batch_size))\n",
    "        for batch_id in tqdm(range(no_batches)):\n",
    "            ## Get batch\n",
    "            inputs, labels, miss_chars, input_lengths = get_current_batch_data(\n",
    "                cur_epoch_data_list = cur_epoch_train_data_list, \n",
    "                batch_id = batch_id, \n",
    "                batch_size = batch_size,\n",
    "                vocab_size = vocab_size\n",
    "            )\n",
    "            \n",
    "            ## Embeddings should be of dtype long\n",
    "            inputs = torch.from_numpy(inputs).long()\n",
    "            \n",
    "            ## Convert to torch tensors\n",
    "            labels = torch.from_numpy(labels).float()\n",
    "            miss_chars = torch.from_numpy(miss_chars).float()\n",
    "            input_lengths = torch.from_numpy(input_lengths).long()\n",
    "\n",
    "            if(cuda==True):\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                miss_chars = miss_chars.cuda()\n",
    "                input_lengths = input_lengths.cuda()\n",
    "\n",
    "            ## Zero the parameter gradients\n",
    "            model.optimizer.zero_grad()\n",
    "            \n",
    "            ## Forward Pass, Loss calculation, Backward Pass, Optimize\n",
    "            outputs = model(inputs, input_lengths, miss_chars)\n",
    "            loss, miss_penalty = model.calculate_loss(outputs, labels, input_lengths, miss_chars, cuda)\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "\n",
    "            ## store loss\n",
    "            train_loss += loss.item()\n",
    "            train_miss_penalty += miss_penalty.item()\n",
    "\n",
    "        # Test model after epoch\n",
    "        test_loss, test_miss_penalty = test(\n",
    "            epoch = epoch,\n",
    "            model = model,\n",
    "            total_epochs = total_epochs,\n",
    "            encoded_test_word_list = encoded_test_word_list,\n",
    "            batch_size = batch_size,\n",
    "            vocab_size = vocab_size,\n",
    "            cuda = cuda\n",
    "        )\n",
    "        model.train()\n",
    "\n",
    "        # Store losses\n",
    "        epoch_list.append(epoch)\n",
    "        train_loss = (train_loss / no_batches)\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_miss_penalty = (train_miss_penalty/ no_batches)\n",
    "        train_miss_penalty_list.append(train_miss_penalty)\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_miss_penalty_list.append(test_miss_penalty)\n",
    "\n",
    "        # Save Losses\n",
    "        df_loss = pd.DataFrame(\n",
    "            {\n",
    "                \"epoch\": epoch_list,\n",
    "                \"train_loss\": train_loss_list,\n",
    "                \"train_miss_penalty\": train_miss_penalty_list,\n",
    "                \"test_loss\": test_loss_list,\n",
    "                \"test_miss_penalty\": test_miss_penalty_list\n",
    "            }\n",
    "        )\n",
    "        df_loss_location = f\"{model_output_location}/df_loss.csv\"\n",
    "        df_loss.to_csv(df_loss_location, index=False)\n",
    "\n",
    "        # Save model\n",
    "        if(epoch % save_every == 0):\n",
    "            model_path = f\"{model_output_location}/models\"\n",
    "            model_file_name = f\"{model_path}/model_epoch_{str(epoch).zfill(4)}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': model.optimizer.state_dict(),\n",
    "                'train_loss': train_loss,\n",
    "                'test_loss': test_loss,\n",
    "            }, model_file_name)\n",
    "        \n",
    "        # Print Info\n",
    "        print(f\"Epoch: {epoch} | Train Loss: {train_loss} | Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [52:56<00:00, 167.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 12.024575885973478 | Test Loss: 11.007060623168945\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "\ttotal_epochs = 1,\n",
    "\tencoded_train_words_location = \"../data/gru_model/encoded_train_words.pickle\",\n",
    "\tencoded_test_words_location = \"../data/gru_model/encoded_test_words.pickle\",\n",
    "\tbatch_size = 10000,\n",
    "\tvocab_size = 26,\n",
    "\tcuda = False,\n",
    "    reset_after = 1,\n",
    "\tsave_every = 1,\n",
    "\tmodel_output_location = \"model_output\",\n",
    "\tgru_hidden_dim = 512,\n",
    "\tgru_num_layers = 2,\n",
    "\tchar_embedding_dim = 128,\n",
    "\tmissed_char_linear_dim = 256,\n",
    "\tnn_hidden_dim = 256,\n",
    "\tgru_dropout = 0.3,\n",
    "\tlearning_rate = 0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_model import load_model\n",
    "from test import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lenovo\\Downloads\\abhishek\\git\\learning_material\\challenges\\hangman_challenge\\gru_model_code\\train.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Downloads/abhishek/git/learning_material/challenges/hangman_challenge/gru_model_code/train.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Load Model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Downloads/abhishek/git/learning_material/challenges/hangman_challenge/gru_model_code/train.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m saved_model_output_location \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./model_output/models_2/best_GRU_2_512.pth\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lenovo/Downloads/abhishek/git/learning_material/challenges/hangman_challenge/gru_model_code/train.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(saved_model_output_location)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\Downloads\\abhishek\\git\\learning_material\\challenges\\hangman_challenge\\gru_model_code\\load_model.py:16\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(saved_model_output_location, vocab_size, cuda, gru_hidden_dim, gru_num_layers, char_embedding_dim, missed_char_linear_dim, nn_hidden_dim, gru_dropout, learning_rate)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\n\u001b[0;32m      5\u001b[0m     saved_model_output_location,\n\u001b[0;32m      6\u001b[0m     vocab_size \u001b[39m=\u001b[39m \u001b[39m26\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     learning_rate \u001b[39m=\u001b[39m \u001b[39m0.0005\u001b[39m\n\u001b[0;32m     15\u001b[0m ):\n\u001b[1;32m---> 16\u001b[0m     saved_model_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(saved_model_output_location)\n\u001b[0;32m     17\u001b[0m     model \u001b[39m=\u001b[39m HangmanGRU(\n\u001b[0;32m     18\u001b[0m         vocab_size \u001b[39m=\u001b[39m vocab_size,\n\u001b[0;32m     19\u001b[0m         gru_hidden_dim \u001b[39m=\u001b[39m gru_hidden_dim,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m         learning_rate \u001b[39m=\u001b[39m learning_rate\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     27\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(saved_model_output[\u001b[39m\"\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:1028\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1027\u001b[0m         \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1028\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:1256\u001b[0m, in \u001b[0;36m_legacy_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1254\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1255\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1256\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   1258\u001b[0m deserialized_storage_keys \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39mload(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1260\u001b[0m offset \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mtell() \u001b[39mif\u001b[39;00m f_should_read_directly \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:1193\u001b[0m, in \u001b[0;36m_legacy_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     obj\u001b[39m.\u001b[39m_torch_load_uninitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m     \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m     \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m     typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1193\u001b[0m         wrap_storage\u001b[39m=\u001b[39mrestore_location(obj, location),\n\u001b[0;32m   1194\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1195\u001b[0m         _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1196\u001b[0m     deserialized_objects[root_key] \u001b[39m=\u001b[39m typed_storage\n\u001b[0;32m   1197\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    380\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 381\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[0;32m    382\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    383\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:274\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    273\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 274\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[0;32m    275\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    276\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py:258\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    255\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    259\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    260\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    261\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    262\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    263\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "## Load Model\n",
    "saved_model_output_location = \"./model_output/models_2/best_GRU_2_512.pth\"\n",
    "model = load_model(saved_model_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_words_location = \"../data/gru_model/encoded_test_words.pickle\"\n",
    "encoded_test_word_list = pickle.load(open(encoded_test_words_location, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_miss_penalty = test(\n",
    "\tepoch = 1,\n",
    "\tmodel = model,\n",
    "\ttotal_epochs = 1,\n",
    "\tencoded_test_word_list = encoded_test_word_list,\n",
    "\tbatch_size = 10000,\n",
    "\tvocab_size = 26,\n",
    "\tcuda = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.005796813964844, -16.91201858520508)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_miss_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_word = \"h*p**\"\n",
    "guessed_letter_list = [\"y\", \"n\", \"h\", \"p\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\n",
    "    model = model,\n",
    "    incomplete_word = incomplete_word, \n",
    "    guessed_letter_list = guessed_letter_list,\n",
    "    vocab_size = 26\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
